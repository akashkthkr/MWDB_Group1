'''
 Task 4: Locality-Sensitive Hashing
 
– Implement a Locality Sensitive Hashing (LSH) tool, which takes as input (a) the number of layers, L, (b) the number of hashes per layer, κ, 
and (c) a set of vectors (generated by other tasks) as input and creates an in-memory index structure containing the given set of vectors. See
 ”Near-Optimal Hashing Algorithms for the Approximate Nearest Neighbor in High Dimensions” (by Alexandr Andoni and Piotr Indyk). Communications of the ACM, vol. 51, no. 1, 2008, pp. 117-122.
 
– Implement similar image search using this index structure:
 
∗ given a folder of images and one of the three feature models, the images are stored in an LSH data structure (the program also outputs the size of the index structure in bytes), and
 
∗ given image and t, the tool outputs the t most similar images; it also outputs
 
· the numbers of buckets searched as well as the unique and overall number of images considered
 
· false positive and miss rates.

'''
'''
Inputs:
(a) the number of layers
(b) the number of hashes per layer
κ, and (c) a set of vectors (generated by other tasks) 

Intermediary:
In memory index structure LSH to hold the set of vectors 
'''
'''
Second Part:
Image Search implementation using index struct
Inputs:
Folder of images : 
3 Feature models(Hog,elbp etc)
Store image in LSH Data Struct
Test Case :
Given a image and t (5 most similar)
'''
'''
Output:
Display the size of the files in bytes : outputs the t most similar images
Number of buckets searched as well as unique overall number of images considered
False positive and miss rates
'''

'''Running the code:
$ python lsh.py
    Enter the number of Layers: <number>
    Enter the number of Hashes per layer: <number>
    Enter the ImageId: <image_id>
    Enter the value of t: <task_number>
'''
import sys
import json
import pickle
from pathlib import Path
from constants.Constants_Phase3 import OUTPUTS_PATH
import os
import numpy as np
from termcolor import colored

wind_size = 5
offset = np.random.randint(wind_size)


def euclidean_dist_square(x, y):
    x = np.array(x)
    y = np.array(y)
    return np.linalg.norm(x - y)


class Lsh(object):

    def __init__(self, number_of_hashes_per_layer, number_of_features, num_layers=2):
        self.num_layers = num_layers
        self.number_of_hashes_per_layer = number_of_hashes_per_layer
        self.number_of_features = number_of_features
        self.random_planes = [np.random.randn(self.number_of_hashes_per_layer, self.number_of_features)
                              for _ in range(self.num_layers)]
        self.layers = [dict() for i in range(self.num_layers)]

    def get_combined_hash_value(self, planes, input_point, j):
        input_point = np.array(input_point)
        projections = planes.dot(input_point)
        # projections = projections/50
        # val= "".join([str(int(i)+j) for i in projections])
        # return val
        return "".join(['1' if i > 0 else '0' for i in projections])

    def add_to_index_structure(self, input_feature, image_id=''):
        value = tuple(input_feature)
        for i, layer in enumerate(self.layers):
            layer.setdefault(self.get_combined_hash_value(self.random_planes[i], input_feature, 0), []).append(
                (value, image_id))

    def query(self, feature, num_results=None, distance_func=None):
        image_hits = set()
        calculate_distance = euclidean_dist_square

        for i, layer in enumerate(self.layers):
            combined_hash_value = self.get_combined_hash_value(self.random_planes[i], feature, 0)
            image_hits.update(layer.get(combined_hash_value, []))
        j = 1

        while len(image_hits) < num_results:
            for i, layer in enumerate(self.layers):
                combined_hash_value = self.get_combined_hash_value(self.random_planes[i], feature, j)
                image_hits.update(layer.get(combined_hash_value, []))
                combined_hash_value = self.get_combined_hash_value(self.random_planes[i], feature, 0 - j)
                image_hits.update(layer.get(combined_hash_value, []))
                # print(len(image_hits))
            j += 1

        image_hits = [(hit_tuple[1], calculate_distance(feature, np.asarray(hit_tuple[0])))
                      for hit_tuple in image_hits]
        image_hits.sort(key=lambda v: v[1])

        result = image_hits[:num_results] if num_results else image_hits
        return result, len(image_hits), len(set(image_hits))

    def save_to_json(filename, object_to_store):
        with open(filename, 'w') as json_file:
            json.dump(object_to_store, json_file)

    def save_to_pickle(filename, object_to_store):
        with open(filename, 'wb') as pickle_file:
            pickle.dump(object_to_store, pickle_file)

    def save_result(self, result):
        output_folder = OUTPUTS_PATH
        reduced_pickle_file_folder = os.path.join(Path(os.path.dirname(__file__)).parent,
                                                  OUTPUTS_PATH, 'pickle_files')

        self.save_to_pickle(output_folder + "partitions.pk", reduced_pickle_file_folder)
        self.save_to_json(output_folder + "lsh_data.json", result)
# image_hits = [(os.path.join(OUTPUTS_PATH, hit_tuple[1]),
#                calculate_distance(feature, hit_tuple[0])) for hit_tuple in image_hits]
